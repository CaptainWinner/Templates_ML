{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#BERT basics"
      ],
      "metadata": {
        "id": "PEZr1_-uGGZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oUFXKIYGFgS"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
      ],
      "metadata": {
        "id": "4l4nZqEiGOBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
      ],
      "metadata": {
        "id": "DFIvDKBcGO9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['nice movie indeed','I love python programming']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "text_preprocessed.keys()"
      ],
      "metadata": {
        "id": "PktpOdTKGQ9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dict_keys(['input_mask', 'input_type_ids', 'input_word_ids'])"
      ],
      "metadata": {
        "id": "FG0Lez-mGUDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed['input_mask']"
      ],
      "metadata": {
        "id": "ELqBI696GR05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
        "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ],
      "metadata": {
        "id": "_n9gbAclGV9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed['input_type_ids']"
      ],
      "metadata": {
        "id": "E25I08BKGbKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
        "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ],
      "metadata": {
        "id": "mVmtb---GcOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed['input_word_ids']"
      ],
      "metadata": {
        "id": "80xrbPc7GdAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
        "array([[  101,  3835,  3185,  5262,   102,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0],\n",
        "       [  101,  1045,  2293, 18750,  4730,   102,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0]])>"
      ],
      "metadata": {
        "id": "vXBZ5n3DGekT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "101 --> CLS token\n",
        "\n",
        "102 --> SEP token"
      ],
      "metadata": {
        "id": "BOj-YshOGi7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT uses CLS as a special token at the begining of each setence whereas SEP as a special token to separate two sentences or end sinle sentece"
      ],
      "metadata": {
        "id": "g6t4SoYtGkNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(encoder_url)"
      ],
      "metadata": {
        "id": "HfyojKAfGgGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)"
      ],
      "metadata": {
        "id": "TP_-Ot-CGl8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results.keys()"
      ],
      "metadata": {
        "id": "X1DiSwKQGm0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dict_keys(['default', 'encoder_outputs', 'pooled_output', 'sequence_output'])"
      ],
      "metadata": {
        "id": "BjUZxtPoGon6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['sequence_output']"
      ],
      "metadata": {
        "id": "ncfsdNOBGn4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
        "array([[[ 0.07292037,  0.08567802,  0.14476836, ..., -0.0967709 ,\n",
        "          0.08722147,  0.07711098],\n",
        "        [ 0.17839421, -0.19006097,  0.5034945 , ..., -0.0586979 ,\n",
        "          0.32717168, -0.1557853 ],\n",
        "        [ 0.187015  , -0.4338879 , -0.4887509 , ..., -0.15502754,\n",
        "          0.00145202, -0.24470882],\n",
        "        ...,\n",
        "        [ 0.1208308 ,  0.12884231,  0.464535  , ...,  0.07375526,\n",
        "          0.17441988,  0.16522081],\n",
        "        [ 0.07967911, -0.01190642,  0.50225425, ...,  0.13777754,\n",
        "          0.21002221,  0.0062458 ],\n",
        "        [-0.07212636, -0.28303444,  0.5903337 , ...,  0.47551885,\n",
        "          0.16668531, -0.08920398]],\n",
        "\n",
        "       [[-0.0790057 ,  0.36335146, -0.21101563, ..., -0.1718371 ,\n",
        "          0.1629976 ,  0.6724266 ],\n",
        "        [ 0.27883556,  0.43716326, -0.35764703, ..., -0.04463666,\n",
        "          0.38315117,  0.588798  ],\n",
        "        [ 1.2037678 ,  1.0727024 ,  0.4840874 , ...,  0.24921025,\n",
        "          0.40730858,  0.40481782],\n",
        "        ...,\n",
        "        [ 0.08630062,  0.19353887,  0.47540048, ...,  0.1888018 ,\n",
        "         -0.06474137,  0.3131858 ],\n",
        "        [ 0.15887049,  0.28572696,  0.373408  , ...,  0.09309126,\n",
        "         -0.04969583,  0.3876115 ],\n",
        "        [-0.08079858, -0.09572807,  0.26809806, ...,  0.13979636,\n",
        "         -0.06315896,  0.2728837 ]]], dtype=float32)>"
      ],
      "metadata": {
        "id": "ehtQVtvhGp5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['pooled_output']"
      ],
      "metadata": {
        "id": "nK6lrK_kGrMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
        "array([[-0.791774  , -0.21411924,  0.49769488, ...,  0.2446518 ,\n",
        "        -0.47334483,  0.81758696],\n",
        "       [-0.9171231 , -0.4793518 , -0.78656995, ..., -0.6175177 ,\n",
        "        -0.7102687 ,  0.92184293]], dtype=float32)>"
      ],
      "metadata": {
        "id": "hU5iULsiGtVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(bert_results['encoder_outputs'])"
      ],
      "metadata": {
        "id": "weKs4NYpGuQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12"
      ],
      "metadata": {
        "id": "1bshbPCjGvE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are using BERT base model it has 12 encoder layers, that's why above the length of encoder_output is 12. Read more about purpose of each element here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
        "\n",
        "You can see below that last element of encoder_outputs is basically a sequence_output"
      ],
      "metadata": {
        "id": "i5vB-JByGyRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['encoder_outputs'][-1] == bert_results['sequence_output']"
      ],
      "metadata": {
        "id": "0tALPvzPGwFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tf.Tensor: shape=(2, 128, 768), dtype=bool, numpy=\n",
        "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        ...,\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True]],\n",
        "\n",
        "       [[ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        ...,\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True],\n",
        "        [ True,  True,  True, ...,  True,  True,  True]]])>"
      ],
      "metadata": {
        "id": "pNx7fcVyG0mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results['encoder_outputs']"
      ],
      "metadata": {
        "id": "sy09QThVG09U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bert usage (spam/not spam)"
      ],
      "metadata": {
        "id": "ifRXNhQWG5IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "EKWsEou5G7Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"spam.csv\")\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "yvjsmj0fHCev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Category\tMessage\n",
        "0\tham\tGo until jurong point, crazy.. Available only ...\n",
        "1\tham\tOk lar... Joking wif u oni...\n",
        "2\tspam\tFree entry in 2 a wkly comp to win FA Cup fina...\n",
        "3\tham\tU dun say so early hor... U c already then say...\n",
        "4\tham\tNah I don't think he goes to usf, he lives aro..."
      ],
      "metadata": {
        "id": "ANor3UTmHEvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Category').describe()"
      ],
      "metadata": {
        "id": "NQN7hrvHHFga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Message\n",
        "count\tunique\ttop\tfreq\n",
        "Category\t\t\t\t\n",
        "ham\t4825\t4516\tSorry, I'll call later\t30\n",
        "spam\t747\t641\tPlease call our customer service representativ...\t4"
      ],
      "metadata": {
        "id": "1r4lsr5VHMvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Category'].value_counts()"
      ],
      "metadata": {
        "id": "0IqoGNhjHNeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ham     4825\n",
        "spam     747\n",
        "Name: Category, dtype: int64"
      ],
      "metadata": {
        "id": "FU1Azd9FHOpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15% spam emails, 85% ham emails: This indicates class imbalance"
      ],
      "metadata": {
        "id": "UOqiF3hUHQt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spam = df[df['Category']=='spam']\n",
        "df_spam.shape"
      ],
      "metadata": {
        "id": "XGznAq8iHPFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ham = df[df['Category']=='ham']\n",
        "df_ham.shape"
      ],
      "metadata": {
        "id": "tozzhVXwHR3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ham_downsampled = df_ham.sample(df_spam.shape[0])\n",
        "df_ham_downsampled.shape"
      ],
      "metadata": {
        "id": "2ak9g1hzHSvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced = pd.concat([df_ham_downsampled, df_spam])\n",
        "df_balanced.shape"
      ],
      "metadata": {
        "id": "LM4pbKSaHUI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced['Category'].value_counts()"
      ],
      "metadata": {
        "id": "DXd-VHHWHVCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced['spam']=df_balanced['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
        "df_balanced.sample(5)"
      ],
      "metadata": {
        "id": "FDll01usHV2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Cat,Message, Spam (1-spam,0-not)"
      ],
      "metadata": {
        "id": "PHJpbConHWSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split it into training and test data set"
      ],
      "metadata": {
        "id": "yN-mguhRIkHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_balanced['Message'],df_balanced['spam'], stratify=df_balanced['spam'])"
      ],
      "metadata": {
        "id": "H6t_sHJqHXso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(4)"
      ],
      "metadata": {
        "id": "obj9bVy_Imyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets import BERT model and get embeding vectors for few sample statements"
      ],
      "metadata": {
        "id": "IBmeklNSIokz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "W_QO4W6dIn34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_embeding(sentences):\n",
        "    preprocessed_text = bert_preprocess(sentences)\n",
        "    return bert_encoder(preprocessed_text)['pooled_output']"
      ],
      "metadata": {
        "id": "fiXkvv9jIrpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional for understanding:"
      ],
      "metadata": {
        "id": "3NZkszxtIuQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get embeding vectors for few sample words. Compare them using cosine similarity"
      ],
      "metadata": {
        "id": "BTOViQQWIwwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = get_sentence_embeding([\n",
        "    \"banana\", \n",
        "    \"grapes\",\n",
        "    \"mango\",\n",
        "    \"jeff bezos\",\n",
        "    \"elon musk\",\n",
        "    \"bill gates\"\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "GzNvduiKIsbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity([e[0]],[e[1]])"
      ],
      "metadata": {
        "id": "MSsCA02QIzPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[0.9911089]], dtype=float32)"
      ],
      "metadata": {
        "id": "yB7533kVI25p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values near to 1 means they are similar. 0 means they are very different. Above you can use comparing \"banana\" vs \"grapes\" you get 0.99 similarity as they both are fruits"
      ],
      "metadata": {
        "id": "9oWk02fQI0r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity([e[0]],[e[3]])"
      ],
      "metadata": {
        "id": "qJtl7R3MI0__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[0.8470385]], dtype=float32)"
      ],
      "metadata": {
        "id": "0bji5F6MI4Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing banana with jeff bezos you still get 0.84 but it is not as close as 0.99 that we got with grapes"
      ],
      "metadata": {
        "id": "ay4DOc2TI6QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity([e[3]],[e[4]])"
      ],
      "metadata": {
        "id": "uyDTsQtmI15E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[0.98720354]], dtype=float32)"
      ],
      "metadata": {
        "id": "grOaI3ryI7Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jeff bezos and Elon musk are more similar then Jeff bezos and banana as indicated above"
      ],
      "metadata": {
        "id": "KIc16prkI8w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**\n",
        "There are two types of models you can build in tensorflow.\n",
        "\n",
        "(1) Sequential (2) Functional\n",
        "\n",
        "So far we have built sequential model. But below we will build functional model. More information on these two is here: https://becominghuman.ai/sequential-vs-functional-model-in-keras-20684f766057"
      ],
      "metadata": {
        "id": "a9823yhUI-k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ],
      "metadata": {
        "id": "oM7ydvreI79s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/47605558/importerror-failed-to-import-pydot-you-must-install-pydot-and-graphviz-for-py"
      ],
      "metadata": {
        "id": "EFLziujfJC8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "cIrLVEHjJDXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)"
      ],
      "metadata": {
        "id": "hlveiqUkJF5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "NmM5iFyVJHT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "sptxkfzLJISE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.flatten()"
      ],
      "metadata": {
        "id": "ZjnsIfrMJJEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "y_predicted"
      ],
      "metadata": {
        "id": "o7wro9d6JJ6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "cm "
      ],
      "metadata": {
        "id": "lByb2bY6JK0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[154,  33],\n",
        "       [  2, 185]], dtype=int64)"
      ],
      "metadata": {
        "id": "edzTZ1yuJLhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "cHjapi03JL4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_predicted))"
      ],
      "metadata": {
        "id": "05jhMUB4JM7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      0.82      0.90       187\n",
        "           1       0.85      0.99      0.91       187\n",
        "\n",
        "    accuracy                           0.91       374\n",
        "   macro avg       0.92      0.91      0.91       374\n",
        "weighted avg       0.92      0.91      0.91       374\n"
      ],
      "metadata": {
        "id": "TUi0_mnnJN_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    'Enter a chance to win $5000, hurry up, offer valid until march 31, 2021',\n",
        "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
        "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
        "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
        "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
        "]\n",
        "model.predict(reviews)"
      ],
      "metadata": {
        "id": "Q-qXrE5uJSNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[0.8734353 ],\n",
        "       [0.92858446],\n",
        "       [0.8960864 ],\n",
        "       [0.29311982],\n",
        "       [0.13262196]], dtype=float32)"
      ],
      "metadata": {
        "id": "xwxKekQpJSh0"
      }
    }
  ]
}