{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dirty/clean plates"
      ],
      "metadata": {
        "id": "fGP9tk_8Y0vM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparations"
      ],
      "metadata": {
        "id": "6368dCfgZE1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir('../input'))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('../input/plates.zip', 'r') as zip_obj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zip_obj.extractall('/kaggle/working/')\n",
        "    \n",
        "print('After zip extraction:')\n",
        "print(os.listdir('/kaggle/working/'))"
      ],
      "metadata": {
        "id": "F7lXenfpY5Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') "
      ],
      "metadata": {
        "id": "YFYCxbgOZODD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "qwkcUcIaZPf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN = np.array([0.485, 0.456, 0.406])\n",
        "STD = np.array([0.229, 0.224, 0.225])"
      ],
      "metadata": {
        "id": "rjfCdIm4ZTJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = '/kaggle/working/plates/'\n",
        "TRAIN_DIR = 'train'\n",
        "TEST_DIR = 'test'"
      ],
      "metadata": {
        "id": "RhbZwHDzZUSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copytree(os.path.join(DATA_ROOT, TRAIN_DIR), TRAIN_DIR)"
      ],
      "metadata": {
        "id": "6QhyDSO_ZVNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copytree(os.path.join(DATA_ROOT, TEST_DIR), os.path.join(TEST_DIR, 'unknown'))"
      ],
      "metadata": {
        "id": "mvLwLx5iZXyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes and functions"
      ],
      "metadata": {
        "id": "xpwDKny0ZYkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessing:\n",
        "    \"\"\"Class for datasets preprocessing\"\"\"\n",
        "    \n",
        "    def _remove_background(self, path, file):\n",
        "        # TODO: Improve background removing and crop images\n",
        "        img = cv2.imread(path + file)\n",
        "    \n",
        "        img = np.array(img)\n",
        "        height, width = img.shape[:2]\n",
        "        mask = np.zeros([height, width], np.uint8)\n",
        "\n",
        "        bgdModel = np.zeros((1, 65),np.float64)\n",
        "        fgdModel = np.zeros((1, 65),np.float64)\n",
        "\n",
        "        rect = (15, 15, width-15, height-15)\n",
        "        cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "        mask = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
        "        res = img * mask[:, :, np.newaxis]\n",
        "\n",
        "        # Get the background\n",
        "        background = img - res\n",
        "\n",
        "        # Change all pixels in the background that are not black to white\n",
        "        background[np.where((background > [0, 0, 0]).all(axis = 2))] = [255, 255, 255]\n",
        "\n",
        "        res = np.array(background + res)\n",
        "        cv2.imwrite(path + file, res)\n",
        "\n",
        "    def remove_background(self, image_folders):\n",
        "        for path in image_folders:\n",
        "            files = os.listdir(path)\n",
        "            files = list(filter(lambda x: x.endswith('.jpg'), files))\n",
        "\n",
        "            for file in tqdm(files):\n",
        "                self._remove_background(path, file)"
      ],
      "metadata": {
        "id": "a_zqVVpnZZ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        path = self.imgs[index][0]\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ],
      "metadata": {
        "id": "oh_BAeDKZg-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_input(input_tensor, title=''):\n",
        "    image = input_tensor.permute(1, 2, 0).numpy()\n",
        "    image = STD * image + MEAN\n",
        "    plt.imshow(image.clip(0, 1))\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eaqsuXydZjJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = DataPreprocessing()"
      ],
      "metadata": {
        "id": "NBvhu93QZjn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing images background\n",
        "preprocessor.remove_background(image_folders=[\n",
        "    os.path.join(TRAIN_DIR, 'cleaned/'),\n",
        "    os.path.join(TRAIN_DIR, 'dirty/'),\n",
        "    os.path.join(TEST_DIR, 'unknown/')\n",
        "])"
      ],
      "metadata": {
        "id": "ZmDS0hisZkpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=90, fill=255),\n",
        "    transforms.CenterCrop(180),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(hue=(0.1, 0.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR, train_transforms)\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "iT4xeU1fZnFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(train_dataset)"
      ],
      "metadata": {
        "id": "bxmhTC3FZqej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['cleaned', 'dirty']\n",
        "\n",
        "X_batch, y_batch = next(iter(train_dataloader))\n",
        "\n",
        "for x_item, y_item in zip(X_batch, y_batch):\n",
        "    show_input(x_item, title=class_names[y_item])"
      ],
      "metadata": {
        "id": "GNc1CWKWZsFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "CMwqEaEoZu6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, loss, optimizer, scheduler, num_epochs):\n",
        "    accuracies = {'train': []}\n",
        "    losses = {'train': []}\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "        # Each epoch has a training phase\n",
        "        phase = 'train'\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "\n",
        "        # Iterate over data\n",
        "        for inputs, labels in tqdm(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward and backward\n",
        "            with torch.set_grad_enabled(True):\n",
        "                preds = model(inputs)\n",
        "                loss_value = loss(preds, labels)\n",
        "                preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                loss_value.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss_value.item()\n",
        "            running_acc += (preds_class == labels.data).float().mean()\n",
        "        \n",
        "        scheduler.step()\n",
        "            \n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        epoch_acc = running_acc / len(dataloader)\n",
        "\n",
        "        accuracies[phase].append(epoch_acc)\n",
        "        losses[phase].append(epoch_loss)\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
        "\n",
        "    return model, losses, accuracies"
      ],
      "metadata": {
        "id": "NOWaMxQHZv9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose seed for training reproduction\n",
        "seed = 21\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model = models.resnet34(pretrained=True)\n",
        "model = models.resnet50(pretrained=True)\n",
        "# model = models.resnet152(pretrained=True)\n",
        "\n",
        "# Disable grad for all conv layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=1.0)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)# Choose seed for training reproduction\n",
        "seed = 21\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model = models.resnet34(pretrained=True)\n",
        "model = models.resnet50(pretrained=True)\n",
        "# model = models.resnet152(pretrained=True)\n",
        "\n",
        "# Disable grad for all conv layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=1.0)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "z7DObK5CZzgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses, accuracies = train_model(model, train_dataloader, loss,\n",
        "                                        optimizer, scheduler, num_epochs=40)"
      ],
      "metadata": {
        "id": "MYjlHceFZ2An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "for experiment_id in accuracies.keys():\n",
        "    plt.plot(accuracies[experiment_id], label=experiment_id)\n",
        "plt.legend()\n",
        "plt.title('Accuracy')"
      ],
      "metadata": {
        "id": "hBH6_OvtZ4g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "for experiment_id in losses.keys():\n",
        "    plt.plot(losses[experiment_id], label=experiment_id)\n",
        "plt.legend()\n",
        "plt.title('Loss')"
      ],
      "metadata": {
        "id": "vJabqKebZ6BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms for test dataset"
      ],
      "metadata": {
        "id": "JSFtVX5qZ7cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(180),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "test_dataset = ImageFolderWithPaths(os.path.join(TEST_DIR), transform=test_transforms)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=8, shuffle=False, num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "OMlCj44WZ9Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "2OdhEpLrZ-uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions"
      ],
      "metadata": {
        "id": "3LWBXZGsaAzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "test_predictions = []\n",
        "test_img_paths = []\n",
        "for inputs, labels, paths in tqdm(test_dataloader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "        preds = model(inputs)\n",
        "    test_predictions.append(\n",
        "        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n",
        "    test_img_paths.extend(paths)\n",
        "\n",
        "test_predictions = np.concatenate(test_predictions)"
      ],
      "metadata": {
        "id": "KmC_DBL3Z_2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, labels, paths = next(iter(test_dataloader))\n",
        "\n",
        "for img, pred in zip(inputs, test_predictions):\n",
        "    show_input(img, title=pred)"
      ],
      "metadata": {
        "id": "BwlnEgxyaCo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission"
      ],
      "metadata": {
        "id": "k6FBC_cdaFmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})"
      ],
      "metadata": {
        "id": "f7nDmhUnaGyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.63 else 'cleaned')\n",
        "submission_df['id'] = submission_df['id'].str.replace('test/unknown/', '')\n",
        "submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n",
        "submission_df.set_index('id', inplace=True)\n",
        "submission_df.head(n=6)"
      ],
      "metadata": {
        "id": "9A-gQLK2aIXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "DWvgX5FHaNYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv(os.path.join(DATA_ROOT, 'submission.csv'))"
      ],
      "metadata": {
        "id": "GeXBApvyaOqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf train test"
      ],
      "metadata": {
        "id": "bFDAahuiaPum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}